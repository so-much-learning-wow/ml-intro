{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем модули и данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.cross_validation import KFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "X_train = pd.read_csv('data/features.csv')\n",
    "X_test = pd.read_csv('data/features_test.csv')\n",
    "y = X_train['radiant_win']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градиентный бустинг\n",
    "**1.** Удаляем признаки, связанные с исходом матча"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.drop([\n",
    "        'tower_status_radiant',\n",
    "        'duration',\n",
    "        'tower_status_dire',\n",
    "        'radiant_win',\n",
    "        'barracks_status_dire',\n",
    "        'barracks_status_radiant'\n",
    "    ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** Проверяем выборку на наличие пропусков в данных и выводим признаки, данные для которых пропущены"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dire_bottle_time, first_blood_player1, radiant_courier_time, dire_courier_time, radiant_bottle_time, radiant_first_ward_time, dire_flying_courier_time, dire_first_ward_time, first_blood_team, first_blood_time, first_blood_player2, radiant_flying_courier_time\n",
      "Average missings in features with missing data 18958.75\n"
     ]
    }
   ],
   "source": [
    "X_all = pd.concat((X_train, X_test), axis=0)\n",
    "nan_stats = X_all.isnull().sum()\n",
    "features_with_nans = dict(filter(lambda f: f[1] > 0, list(nan_stats.items())))\n",
    "\n",
    "print(', '.join(features_with_nans.keys()))\n",
    "print('Average missings in features with missing data', np.average(list(features_with_nans.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные пропущены в следующих столбцах:\n",
    "```\n",
    "    first_blood_player1,\n",
    "    radiant_flying_courier_time,\n",
    "    first_blood_team,\n",
    "    dire_first_ward_time,\n",
    "    dire_courier_time,\n",
    "    radiant_courier_time,\n",
    "    first_blood_time,\n",
    "    dire_bottle_time,\n",
    "    radiant_first_ward_time,\n",
    "    radiant_bottle_time,\n",
    "    first_blood_player2,\n",
    "    dire_flying_courier_time\n",
    "```\n",
    "Всего 12 столбцов с пропущенными данными. В среднем в этих 12 столбцах пропущено по 18958.75 значений (или ~16.5%). Это прилично, но вполне терпимо.\n",
    "\n",
    "Так как наши данные собраны за первые 5 минут матча, то может оказаться так, что некоторые события за этот интервал еще не произошли (например, **radiant_courier_time** или **dire_bottle_time**) произошли в другой момент времени. А некоторые события (даже **first_blood_team**) теоретически могут не случиться вообще (в случае первой крови такое обычно возможно только при \"китайской\" доте 1 на 1 с мочиловом бараков, а не друг друга).\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.** Заполняем пропуски"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.fillna(0)\n",
    "X_test = X_test.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.** Целевая переменная (исход матча) лежит в столбце **radiant_win**. Мы уже положили ее в переменную `y` на первом шаге (потому что потом дропали столбцы в X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.** Обучаем нашу модель! Пробуем количество деревьев от 10 до 50 с шагом в 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created. N trees is: 10.0 Score is: 0.664686904581\n",
      "Model created. N trees is: 20.0 Score is: 0.682239421827\n",
      "Model created. N trees is: 30.0 Score is: 0.689557054588\n",
      "Model created. N trees is: 40.0 Score is: 0.694170033075\n",
      "Model created. N trees is: 50.0 Score is: 0.697536891311\n",
      "Estimator scores: 0.664686904581, 0.682239421827, 0.689557054588, 0.694170033075, 0.697536891311\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(len(X_train), shuffle=True, n_folds=5, random_state=666)\n",
    "n_estimators_variants = np.linspace(10, 50, num=5)\n",
    "n_estimators_scores = list(range(len(n_estimators_variants)))\n",
    "\n",
    "for i, n_estimators in enumerate(n_estimators_variants):\n",
    "    model = GradientBoostingClassifier(n_estimators=int(n_estimators), random_state=666)\n",
    "    scores = cross_val_score(model, X_train, y=y, cv=cv, scoring='roc_auc')\n",
    "    n_estimators_scores[i] = scores.mean()\n",
    "    print('Model created. N trees is:', n_estimators, 'Score is:', n_estimators_scores[i])\n",
    "\n",
    "print('Estimator scores:', ', '.join(map(str, n_estimators_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классификаторы обучались достаточно быстро: для 30 деревьев — около 5 минут.\n",
    "На кросс-валидации для 30 деревьев получилось качество AUC-ROC **~0.69**. Если увеличить количество деревьев, то оно будет немного выше: на 50 деревьях **~0.7**. Чтобы ускорить работу алгоритма, можно распараллелить обучение (как это делается в XGBoost) или попробовать методы уменьшения размерности. Также подходят советы, которые дали в инструкции: сократить глубину дерева или проверяться на подмножестве объектов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Логистическая регрессия\n",
    "**1.** Обучаем модель и подбираем коэффициент регуляризации. Оформим это в виде функции, потому что нам это еще раз предстоит делать. Не забываем перемасштабировать признаки для логистической регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/universome/dev/courses/intro-into-ml/lib/python3.5/site-packages/sklearn/preprocessing/data.py:167: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created. C value is: 0.0001 Score is: 0.711357235409\n",
      "Model created. C value is: 0.001 Score is: 0.71634178315\n",
      "Model created. C value is: 0.01 Score is: 0.716523079975\n",
      "Model created. C value is: 0.1 Score is: 0.716499294762\n",
      "Model created. C value is: 1 Score is: 0.716495414865\n",
      "Model created. C value is: 10 Score is: 0.716495275724\n",
      "Model created. C value is: 100 Score is: 0.71649516559\n",
      "Model created. C value is: 1000 Score is: 0.716495115813\n",
      "Best C value: 0.01\n"
     ]
    }
   ],
   "source": [
    "def train_logistic_regression(X_train, y):\n",
    "    X_train_scaled = scale(X_train)\n",
    "    cv = KFold(len(X_train), shuffle=True, n_folds=5, random_state=666)\n",
    "    C_variants = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "    C_scores = list(range(len(C_variants)))\n",
    "    for i, C in enumerate(C_variants):\n",
    "        model = LogisticRegression(penalty='l2', C=C, random_state=666)\n",
    "        scores = cross_val_score(model, X_train_scaled, y=y, cv=cv, scoring='roc_auc')\n",
    "        C_scores[i] = scores.mean()\n",
    "        print('Model created. C value is:', C, 'Score is:', C_scores[i])\n",
    "    best_score = max(C_scores)\n",
    "    best_C = C_variants[ C_scores.index(best_score) ]\n",
    "    return best_score, best_C\n",
    "\n",
    "best_score, best_C = train_logistic_regression(X_train, y)\n",
    "print(\"Best C value:\", best_C, 'Score is:', best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия обучается намного быстрее бустинга и ее качество немного выше: **~0.715** при оптимальном параметре C, равным **0.01**.\n",
    "\n",
    "Повышение качества у логистической регрессии может быть обусловлено двумя причинами:\n",
    "\n",
    "1. Выборка действительно разделима \"линейной\" гиперплоскостью (которую легко находит логистическая регрессия), которая при этом не является параллельной координатным осям (которую строят решающие деревья)\n",
    "\n",
    "2. Мы никак не учитывали возможность переобучения решающего леса, поэтому он может дать качество получше, если попробовать прюнинг\n",
    "\n",
    "[1] https://www.quora.com/What-are-the-advantages-of-logistic-regression-over-decision-trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** Удаляем категориальные признаки из выборки и повторяем предыдущую процедуру."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.drop([\n",
    "        'lobby_type',\n",
    "        'r1_hero',\n",
    "        'r2_hero',\n",
    "        'r3_hero',\n",
    "        'r4_hero',\n",
    "        'r5_hero',\n",
    "        'd1_hero',\n",
    "        'd2_hero',\n",
    "        'd3_hero',\n",
    "        'd4_hero',\n",
    "        'd5_hero'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/universome/dev/courses/intro-into-ml/lib/python3.5/site-packages/sklearn/preprocessing/data.py:167: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created. C value is: 0.0001 Score is: 0.711322562411\n",
      "Model created. C value is: 0.001 Score is: 0.716346505099\n",
      "Model created. C value is: 0.01 Score is: 0.716528826331\n",
      "Model created. C value is: 0.1 Score is: 0.716504145319\n",
      "Model created. C value is: 1 Score is: 0.716500102191\n",
      "Model created. C value is: 10 Score is: 0.71650001162\n",
      "Model created. C value is: 100 Score is: 0.716499903472\n",
      "Model created. C value is: 1000 Score is: 0.71649991299\n",
      "Best C value: 0.01\n"
     ]
    }
   ],
   "source": [
    "best_score, best_C = train_logistic_regression(X_train, y)\n",
    "print(\"Best C value:\", best_C, 'Score is:', best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После удаления категориальных признаков качество осталось на прежнем уровне (даже на тысячные доли ухудшилось). Значит, они практически не влияли на построение предсказания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.** Количество уникальных героев в матчах есть в файле `heroes.csv` Оно равно **113**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.** Теперь нужно преобразовать категориальные признаки для героев по принципу, похожему на бинаризацию, только кодирование троичное. Оформим это в виде функции, потому что нам потом еще для тестовой выборки это делать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('data/features.csv')\n",
    "X_train = X_train.drop([\n",
    "        'tower_status_radiant',\n",
    "        'duration',\n",
    "        'tower_status_dire',\n",
    "        'radiant_win',\n",
    "        'barracks_status_dire',\n",
    "        'barracks_status_radiant',\n",
    "        'lobby_type'\n",
    "    ], axis=1)\n",
    "X_train = X_train.fillna(0)\n",
    "\n",
    "def get_hero_features(data):\n",
    "    heros_amount = 113\n",
    "    X_pick = np.zeros((data.shape[0], heros_amount))\n",
    "    for i, match_id in enumerate(data.index):\n",
    "        for p in range(5):\n",
    "            X_pick[i, data.ix[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "            X_pick[i, data.ix[match_id, 'd%d_hero' % (p+1)]-1] = -1\n",
    "    X_pick_df = pd.DataFrame(X_pick, columns=['hero_' + str(n) for n in range(1, heros_amount + 1)])\n",
    "    return X_pick_df\n",
    "\n",
    "X_train = pd.concat((X_train, get_hero_features(X_train)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/universome/dev/courses/intro-into-ml/lib/python3.5/site-packages/sklearn/preprocessing/data.py:167: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created. C value is: 0.0001 Score is: 0.74289645091\n",
      "Model created. C value is: 0.001 Score is: 0.751711403101\n",
      "Model created. C value is: 0.01 Score is: 0.752020095674\n",
      "Model created. C value is: 0.1 Score is: 0.751986236407\n",
      "Model created. C value is: 1 Score is: 0.751979706802\n",
      "Model created. C value is: 10 Score is: 0.751979235186\n",
      "Model created. C value is: 100 Score is: 0.751979135531\n",
      "Model created. C value is: 1000 Score is: 0.751979146107\n",
      "Best score: 0.752020095674\n"
     ]
    }
   ],
   "source": [
    "best_score, best_C = train_logistic_regression(X_train, y)\n",
    "print(\"Best score:\", best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, качество значительно подросло — до **~0.752**. Это закономерный факт: раньше алгоритм пытался разделить выборку на два класса в пространстве, значения которого были от 1 до 113, воспринимая эти значения как непрерывную величину. Разумеется, это достаточно абсурдно, потому что значения категориальны и простой линией их не разделишь. Теперь алгоритм рисует линии в этих 113 пространствах, значения которых принадлежат множеству {-1,0,1} — это намного логичнее и проще."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.** Сделаем предсказания для тестовой выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/universome/dev/courses/intro-into-ml/lib/python3.5/site-packages/sklearn/preprocessing/data.py:167: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Минимальное значение предсказания: 0.00359114962028\n",
      "Максимальное значение предсказания: 0.99640885038\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(penalty='l2', C=0.01, random_state=666)\n",
    "clf.fit(scale(X_train), y)\n",
    "\n",
    "X_test = pd.read_csv('data/features_test.csv')\n",
    "X_test = X_test.drop('lobby_type', axis=1)\n",
    "X_test = X_test.fillna(0)\n",
    "X_test = pd.concat((X_test, get_hero_features(X_test)), axis=1)\n",
    "\n",
    "predictions = clf.predict_proba(scale(X_test))\n",
    "print('Минимальное значение предсказания:', predictions.min())\n",
    "print('Максимальное значение предсказания:', predictions.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Минимальное значение предсказания равно **~0.0036**, а максимальное — **~0.99**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
